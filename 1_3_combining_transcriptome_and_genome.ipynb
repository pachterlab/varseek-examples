{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import gget\n",
    "import pandas as pd\n",
    "\n",
    "import varseek as vk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = os.path.dirname(os.path.abspath(\"\"))  # if this notebook resides in varseek/notebooks/0_data_download.ipynb, then this retrieves varseek\n",
    "out_dir = os.path.join(data_directory, \"data\", \"vk_build_pipeline_notebook1\")\n",
    "reference_out_dir = os.path.join(data_directory, \"data\", \"reference\")\n",
    "\n",
    "w=54  # window size for varseek build (should be 1 less than kallisto k)\n",
    "threads = 16\n",
    "\n",
    "variants = \"cosmic_cmc\"  # file path to variants csv/tsv file OR one of the supported databases\n",
    "sequences = \"cdna_and_genome\"  # file path to reference sequence fasta file OR, only if 'variants' is in the supported databases, one of the following options is also supported: \"cds\", \"cdna\", \"genome\", \"cdna_and_genome\" - sequences for vk build\n",
    "cosmic_version = 100  # COSMIC version for gget cosmic\n",
    "remove_Ns = True\n",
    "strandedness = False  # strandedness for vk build and the building of the kb index (True = strandedness matters i.e., treat f and rc as 2 different sequences; False = strandedness does not matter i.e., treat f and rc as the same \n",
    "fasta_filters = [\n",
    "    \"substring_alignment_to_reference-equal=none\",  # filter out variants which are a substring of the reference genome\n",
    "    \"pseudoaligned_to_reference_despite_not_truly_aligning-istrue\",  # filter out variants which pseudoaligned to human genome despite not truly aligning\n",
    "    \"alignment_to_reference-equal=none\",  # filter out variants which are capable of being d-listed (given that I filter out the substrings above)\n",
    "    \"number_of_kmers_with_overlap_to_other_VCRSs-max=999999\"  # filter out variants which overlap with other VCRSs in the reference\n",
    "    \"number_of_other_VCRSs_with_overlapping_kmers-max=999999\"  # filter out variants which overlap with other VCRSs in the reference\n",
    "]\n",
    "\n",
    "# os.environ['COSMIC_EMAIL'] = 'your_email'  # to avoid being prompted for email in varseek build\n",
    "# os.environ['COSMIC_PASSWORD'] = 'your_password'  # to avoid being prompted for password in varseek build\n",
    "\n",
    "dlist_reference_source = \"ensembl_grch37_release93\"  # ensembl_grchNUMBER_releaseNUMBER or t2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir_notebook = os.path.join(out_dir, \"notebook_1_newheaders\")\n",
    "reference_out_dir = os.path.join(out_dir, \"reference\")\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "os.makedirs(out_dir_notebook, exist_ok=True)\n",
    "os.makedirs(reference_out_dir, exist_ok=True)\n",
    "\n",
    "if remove_Ns:\n",
    "    max_ambiguous_kv = 0\n",
    "    N_penalty = 1\n",
    "    max_Ns_per_read_length = 0\n",
    "else:\n",
    "    max_ambiguous_kv = None\n",
    "    N_penalty = 0\n",
    "    max_Ns_per_read_length = 0.1\n",
    "\n",
    "if strandedness:\n",
    "    merge_identical_rc = False\n",
    "    bowtie_strandedness = \"--norc\"  # could do --nofw as well\n",
    "    kb_strandedness = \"--strand forward\"\n",
    "else:\n",
    "    merge_identical_rc = True\n",
    "    bowtie_strandedness = \"\"\n",
    "    kb_strandedness = \"\"\n",
    "\n",
    "\n",
    "sequences_total = sequences\n",
    "sequences_cdna = \"cdna\"\n",
    "sequences_genome = \"genome\"\n",
    "out_dir_kv_build_cdna = os.path.join(out_dir_notebook, \"kv_cdna\")\n",
    "kv_build_vcrs_fa_path_cdna = os.path.join(out_dir_kv_build_cdna, \"vcrs_cdna.fa\")\n",
    "out_dir_kv_build_genome = os.path.join(out_dir_notebook, \"kv_genome\")\n",
    "kv_build_vcrs_fa_path_genome = os.path.join(out_dir_kv_build_genome, \"vcrs_genome.fa\")\n",
    "\n",
    "os.makedirs(out_dir_kv_build_cdna, exist_ok=True)\n",
    "os.makedirs(out_dir_kv_build_genome, exist_ok=True) \n",
    "\n",
    "out_dir_kv_build = os.path.join(out_dir_notebook, f\"kv_{sequences}\")\n",
    "kv_build_vcrs_fa_path = os.path.join(out_dir_kv_build, \"vcrs.fa\")\n",
    "os.makedirs(out_dir_kv_build, exist_ok=True)\n",
    "\n",
    "cosmic_csv = os.path.join(reference_out_dir, \"cosmic\", f\"CancerMutationCensus_AllData_v{cosmic_version}_GRCh37_gget_mutate_with_cdna\")  # output of varseek\n",
    "k = w + 1\n",
    "\n",
    "mutation_metadata_df_path = os.path.join(out_dir_kv_build, \"mutation_metadata_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run kv build for transcriptome with save_variants_updated_csv=True, and merge_headers=False\n",
    "vk.build(\n",
    "    sequences=sequences_cdna,\n",
    "    variants=variants,\n",
    "    out=out_dir_kv_build_cdna,\n",
    "    reference_out_dir=reference_out_dir,\n",
    "    save_variants_updated_csv=True,\n",
    "    ...\n",
    ")\n",
    "\n",
    "# load in the df_cdna, and set df_cdna['variant_source'] = 'cdna'\n",
    "df_cdna = pd.read_csv(os.path.join(out_dir_kv_build_cdna, \"mutation_metadata_updated.csv\"))\n",
    "df_cdna['variant_source'] = 'cdna'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run kv build with for genome save_variants_updated_csv=True, and merge_headers=False\n",
    "vk.build(\n",
    "    sequences=sequences_genome,\n",
    "    variants=cosmic_csv,  # generated above\n",
    "    out=out_dir_kv_build_genome,\n",
    "    reference_out_dir=reference_out_dir,\n",
    "    cosmic_email = os.getenv('COSMIC_EMAIL'),\n",
    "    cosmic_password = os.getenv('COSMIC_PASSWORD'),\n",
    "    seq_id_column = \"chromosome\",\n",
    "    var_column = \"mutation_genome\",\n",
    "    save_variants_updated_csv=True,\n",
    "    ...\n",
    ")\n",
    "\n",
    "# load in the df_genome, and set df_genome['variant_source'] = 'genome'\n",
    "df_genome = pd.read_csv(os.path.join(out_dir_kv_build_genome, \"mutation_metadata_updated.csv\"))\n",
    "df_genome['variant_source'] = 'genome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the results\n",
    "df_combined = pd.concat([df_cdna, df_genome], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if desired, merge headers at this stage, come up with new vcrs_ids, and write a new fasta and a new id:header dict; and for rows with cdna and genome in the same header, make sure df_combined['variant_source'] = 'mixed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run vk info with columns for vcrs_id, vcrs_sequence, variant_source, vcrs_header\n",
    "# - and, if and only if I did not merge headers, - seqID, mutation, chromosome, and mutation_genome (for making header_cdna and header_genome within the function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - no need to filter out genome entries that are equal to cdna in vk info\n",
    "# - no need to label any entries as \"unsplicedENSTâ€¦\"\n",
    "# \t- Change helper functions accordingly"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
